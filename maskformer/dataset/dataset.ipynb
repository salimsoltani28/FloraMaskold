{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = '/mnt/gsdata/projects/panops/Labeled_data_seprated_in_Folder/image_all'\n",
    "img_mask = '/mnt/gsdata/projects/panops/Labeled_data_seprated_in_Folder/image_mask_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/as2114/miniconda3/envs/mask2former/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import MaskFormerImageProcessor\n",
    "\n",
    "def get_preprocessor():\n",
    "    # Create a preprocessor\n",
    "    return MaskFormerImageProcessor(ignore_index=0, reduce_labels=False, do_resize=False, do_rescale=False, do_normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717829/4167767847.py:6: FutureWarning: `reduce_labels` is deprecated and will be removed in version 4.44.0 for `MaskFormerImageProcessor.__init__`. Use `do_reduce_labels` instead.\n",
      "  return MaskFormerImageProcessor(ignore_index=0, reduce_labels=False, do_resize=False, do_rescale=False, do_normalize=False)\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch, preprocessor=get_preprocessor()):\n",
    "    inputs = list(zip(*batch))\n",
    "    images = inputs[0]\n",
    "    segmentation_maps = inputs[1]\n",
    "    # this function pads the inputs to the same size,\n",
    "    # and creates a pixel mask\n",
    "    # actually padding isn't required here since we are cropping\n",
    "    batch = preprocessor(\n",
    "        images,\n",
    "        segmentation_maps=segmentation_maps,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    batch[\"original_images\"] = inputs[2]\n",
    "    batch[\"original_segmentation_maps\"] = inputs[3]\n",
    "    \n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 41385 img name :Fagus sylvatica0003446.jpg mask_name :mask_Fagus sylvatica0003446.jpgidx: 67290 img name :Quercus petraea0001003.jpg mask_name :mask_Quercus petraea0001003.jpgidx: 75067 img name :Sorbus aucuparia0007000.jpg mask_name :mask_Sorbus aucuparia0007000.jpg\n",
      "\n",
      "\n",
      "idx: 45194 img name :Fagus sylvatica0007122.jpg mask_name :mask_Fagus sylvatica0007122.jpg\n",
      "idx: 17426 img name :Aesculus hippocastanum0007424.jpg mask_name :mask_Aesculus hippocastanum0007424.jpg\n",
      "idx: 63847 img name :Prunus avium0007600.jpg mask_name :mask_Prunus avium0007600.jpg\n",
      "idx: 70450 img name :Sorbus aucuparia0002554.jpg mask_name :mask_Sorbus aucuparia0002554.jpg\n",
      "\n",
      "idx: 18428 img name :Aesculus hippocastanum0008426.jpg mask_name :mask_Aesculus hippocastanum0008426.jpg\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/as2114/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/as2114/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/as2114/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_744704/1394133895.py\", line 27, in __getitem__\n    mask = Image.open(mask_path).convert(\"L\")  # Assuming mask is in grayscale\n  File \"/home/as2114/miniconda3/envs/mask2former/lib/python3.8/site-packages/PIL/Image.py\", line 3277, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '/mnt/gsdata/projects/panops/Labeled_data_seprated_in_Folder/image_mask_all/mask_Quercus petraea0001003.jpg'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Iterate through the DataLoader\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, masks \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(images\u001b[38;5;241m.\u001b[39mshape, masks\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Here you would pass images and masks to your model for training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/as2114/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/as2114/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/as2114/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_744704/1394133895.py\", line 27, in __getitem__\n    mask = Image.open(mask_path).convert(\"L\")  # Assuming mask is in grayscale\n  File \"/home/as2114/miniconda3/envs/mask2former/lib/python3.8/site-packages/PIL/Image.py\", line 3277, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '/mnt/gsdata/projects/panops/Labeled_data_seprated_in_Folder/image_mask_all/mask_Quercus petraea0001003.jpg'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 66204 img name :Prunus avium0009957.jpg mask_name :mask_Prunus avium0009957.jpg"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        #for mask name append mask_ in front of image name\n",
    "        mask_name = 'mask_'+img_name\n",
    "        \n",
    "        print(f'idx: {idx} img name :{img_name} mask_name :{mask_name}')\n",
    "        \n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # Assuming mask is in grayscale\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        \n",
    "        return image, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loader(config):\n",
    "    \n",
    "    train_dataset = config.train\n",
    "    train_config = config.meta[train_dataset]\n",
    "\n",
    "    train_dat, val_dat, test_dat, columns = parse_dataset(train_config)\n",
    "\n",
    "\n",
    "    dataset_train = build_dataset(is_train=True, dataframe=train_dat, config=config, col=columns, modality=modality)\n",
    "    print('successfully build train dataset')\n",
    "\n",
    "    dataset_test = build_dataset(is_train=False, dataframe=test_dat, config=config, col=columns, modality=modality)\n",
    "    print(f'local rank {local_rank} / global rank {dist.get_rank()} \\\n",
    "        successfully build test dataset')\n",
    "    \n",
    "    \n",
    "    \n",
    "    sampler_test = torch.utils.data.SequentialSampler(dataset_test)\n",
    "    \n",
    "    data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        sampler=sampler_train,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        collate_fn=collate_fn ### NOTEL THIS ###\n",
    "    )\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test,\n",
    "        sampler=sampler_test,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        collate_fn=collate_fn ### NOTEL THIS ###\n",
    "    )\n",
    "\n",
    "\n",
    "    return dataset_train, data_loader_train\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask2former",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
